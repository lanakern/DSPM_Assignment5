---
title: 'Assignment V: GitHub and the ticketmaster.com API'
subtitle: 'Data Science Project Management | Winter Term 2020 / 2021' 
author: 'Submitted by Lana Kern (Student ID: 5395819)'
date: 'February 16, 2021'
output: 
    html_document:
      toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\

I worked together with Michael Lyubkin (Student ID: 4168485), Martin Scheerer (Student ID: 5631373), Anton HÃ¶hl (Student ID: 5637078), Jingwen Xu (Student ID: 5631584) and Simon Metzger (Student ID: 5635087). 
I hereby assure that my submission is in line with the *Code of Conduct*  outlined on the lecture slides. 

\

## General setup

Before I present the solutions, I clear my workspace as well as install (if necessary)
and load the packages that are needed throughout the assignment.

```{r general, message=FALSE}
# clear workspace
rm(list = ls()) 

# Check if needed packages have already been installed. If not, packages are installed. 
if (!require("httr")) install.packages("httr")  
if (!require("jsonlite")) install.packages("jsonlite") 
if (!require("dplyr")) install.packages("dplyr") 
if (!require("ggplot2")) install.packages("ggplot2") 

# Load packages
library(httr)  # for implementing the HTTP methods like GET() in R
library(jsonlite)  # for converting JSON object in R object using fromJSON()
library(dplyr)  # for data manipulation functions
library(ggplot2)  # to create the map
```


\

## Exercise 1: Setting up a new GitHub repository

The link to my personal GitHub account where the project's version history is documented is:
<https://github.com/lanakern/DSPM_Assignment5.git> 

\

## Exercise 2: Getting to know the API

The most important features and functionalities of the Ticketmaster *Discovery API* for this assignment are:

* The Ticketmaster Discovery API allows one to search for events, attractions, or venues in different countries. 

* The root URL for the *Discover API* is: `https://app.ticketmaster.com/discovery/v2/` where `discovery` denotes the package and `v2` the version.

  + To find all venues the base URL for the `GET()` request is: `https://app.ticketmaster.com/discovery/v2/venues`. 
  
  + This base URL can be expanded by, for example, specifying the country. 

* To run a successful API call, one needs to pass an API key in the `apikey` query parameter. My retrieved valid API key from the API Explorer is stored in a separate script called `api_key_ticketmaster.R` in order to comply to the common secrecy practices. The `api_key_ticketmaster.R` is also stored in the R project, but added to the `.gitignore` file so that it is not tracked by GIT. Most importantly, it does not appear in my public GitHub repository. 

* The rate limit is 5000 API calls per day and 5 requests per second.



\

## Exercise 3: Interacting with the API - the basics

The following packages are needed to interact with the APIs using R and already loaded in the *General setup* section:

* The `{httr}` package is a tidyverse package that is needed to implement the HTTP methods in R. It includes functions for the most important http verbs such as `GET()`.

* The `{jsonlite}` package is needed in order to convert a JSON object into an R object by using the provided function `fromJSON()`. 


Next, a first `GET()` request is performed, that searches for event venues in Germany. The following URL is constructed by using the information from Exercise 2, the venue search of the ticketmaster API explorer (*https://developer.ticketmaster.com/api-explorer/v2/*) and the documentation of the venue search (*https://developer.ticketmaster.com/products-and-docs/apis/discovery-api/v2/#search-venues-v2*). 

```{r ex3_first_GET_request}
# load API key into R and store it in R under the name api_key
# if your structure of your api file is different, please store it here under the
# name "api_key". This is necessary because the "api_key" is used multiple times in the code. 
api_key <- source("api_key_ticketmaster.R")[[1]]

# perform GET request
resp_venues_ger <-
  GET(url = "https://app.ticketmaster.com/discovery/v2/venues.json?",
      query = list(
        apikey = api_key,    # provide secret API key to successfully call API
        countryCode = "DE",  # set countryCode to Germany
        locale = "*"         # use * to match all locales
      )
  )

# check status: if status code starts with a 2 the server received my request
status_code(resp_venues_ger)  # = 200 -> success

# extract the content from the response object using the content() function
# I use the non-error prone way: I specify as = "text" so that the content() function
# returns a character vector containing the JSON object...
content_venues_ger_json <- content(resp_venues_ger, as = "text")

# ... then I convert the JSON object into an R object by using the fromJSON() function
content_venues_ger <- fromJSON(content_venues_ger_json)
```

The list element `content_venues_ger` consists of three elements: `_embedded`, `_links` and `page`. 

* The list element `_embedded` contains a data frame called `venues` which contains the variables we are interested in. More precisely, the data frame `venues` contains 20 observations of 19 variables. 

* The `_links` element contains information about the URLs (stored as *href*) needed to perform a `GET()` request. The `self` element shows the URL that was used to perform the `GET()` request above. The `first` element shows the URL needed to extract the first 20 venues (yields same result as using the URL from `self` in this case). The `next` and `last` element shows the URL needed to extract the next 20 venues and the last 20 venues respectively. Additionally, from the URLs I learn that one can specify the `size` and `page` parameter in the query. 

* Of particular interest for this assignment is also the page element which contains information about the number of entries per page (stored in `size`), the number of total venues (stored in `totalElements`), the number of total Pages (stored in `totalPages`) and the current page number (stored in `number`). 

\

Lastly, the `name`, the `city`, the `postalCode` and `address`, as well as the `url` and the `longitude` and `latitude` of the venues are extracted to a data frame. 

```{r ex3_dataframe}
# the relevant information is stored in the venues part of the list element "_embedded"
# variables of interest are extracted and stored in a data frame called df_venues
df_venues <- data.frame(
  "name" = content_venues_ger$`_embedded`$venues$name, 
  "city" = content_venues_ger$`_embedded`$venues$city$name, 
  "postalCode" = content_venues_ger$`_embedded`$venues$postalCode, 
  "address" = content_venues_ger$`_embedded`$venues$address$line1,
  "url" = content_venues_ger$`_embedded`$venues$url,
  "longitude" = content_venues_ger$`_embedded`$venues$location$longitude,
  "latitude" = content_venues_ger$`_embedded`$venues$location$latitude
)

# show structure of data frame
# structure is similar to the structure of the task sheet
str(df_venues)
```

\



## Exercise 4: Interacting with the API - advanced

I take a closer look at the list element named `page` and recognize that my `GET()` request from Exercise 3 did not return *all* event locations in Germany. More precisely, it only returned the first 20 venues. In the following, I find out how many venues in Germany exist at all and on how many pages they are contained.

```{r ex4_page_result}
# how many results did my GET request yield?
result_per_page <- as.numeric(content_venues_ger$page$size)  # 20
result_per_page 

# how many results are there in total?
n <- as.numeric(content_venues_ger$page$totalElements)  # 12238
n

# I adjust the size parameter, i.e. the results per page, because this
# makes the for loop faster.
size_param <- 500

# on how many full pages are the venues if on one page are 500 results
full_pages <- as.numeric(floor(n/size_param))  # 24
full_pages

# how many venues are on last page (page 25)?
results_last_page <- n - (full_pages * size_param)  # 238
results_last_page


# for loop for full pages
#########################

# calculate number of results from full pages
n_rows <- size_param * full_pages  

# create empty data frame with correct dimensions, i.e. number of rows are results 
# from full pages
# the data frame is filled during the loop 
df_venues_all <- data.frame(
  "name" = character(n_rows), 
  "city" = character(n_rows), 
  "postalCode" = character(n_rows), 
  "address" = character(n_rows),
  "url" = character(n_rows), 
  "longitude" = character(n_rows),
  "latitude" = character(n_rows)
)

# important for the loop: first page starts with 0. Thus, the number of pages
# for the loop must be reduced by one. 
# this can also be seen in the _links and _page element of the list `content_venues_ger`:
# URL for last page equals 611 but number of total pages is 612
loop_pages <- full_pages - 1 

for (i in 0:loop_pages) {
  
  # perform GET request for each page
  resp_venues_ger_pagei <-
    GET(url = "https://app.ticketmaster.com/discovery/v2/venues.json?",
        query = list(
          countryCode = "DE",  # set countryCode as Germany
          apikey = api_key,    # provide secret API key to successfully call API
          page = i,            # page number
          locale = "*",        # use * to match all locales
          size = size_param    # adjust results per page
        )
    )
  
  
  # extract content from response object
  content_json_pagei <- content(resp_venues_ger_pagei, as = "text")
  
  # convert JSON object in R object
  content_venues <- fromJSON(content_json_pagei)
  
  # create data frame for each page
  # sometimes location element is missing. In this case, I set values of 
  # longitude  and latitude to NA
  if (is.null(content_venues$`_embedded`$venues$location$longitude)) {
    df_venues_pagei <- data.frame(
      "name" = content_venues$`_embedded`$venues$name, 
      "city" = content_venues$`_embedded`$venues$city$name, 
      "postalCode" = content_venues$`_embedded`$venues$postalCode, 
      "address" = content_venues$`_embedded`$venues$address$line1,
      "url" = content_venues$`_embedded`$venues$url,
      "longitude" = rep(NA, size_param),
      "latitude" = rep(NA, size_param)
    )
  } else {
    df_venues_pagei <- data.frame(
      "name" = content_venues$`_embedded`$venues$name, 
      "city" = content_venues$`_embedded`$venues$city$name, 
      "postalCode" = content_venues$`_embedded`$venues$postalCode, 
      "address" = content_venues$`_embedded`$venues$address$line1,
      "url" = content_venues$`_embedded`$venues$url,
      "longitude" = content_venues$`_embedded`$venues$location$longitude,
      "latitude" = content_venues$`_embedded`$venues$location$latitude
    )
  }

  # create index 
  j <- i + 1
  
  # calculate index to fill empty data frame
  index <- ((j - 1) * size_param + 1):(size_param * j)
  
  # append data frame of each page to full data frame
  df_venues_all[index, ] <- df_venues_pagei
  
  # respect rate limit: 5 requests per second
  # according to the lecture this would be using Sys.sleep(0.2)
  # I don't know why, but using this rate limit my code did not work.
  # I always received a HTTP status code of 429 meaning that I made too many requests.
  # Thus, I use a more conservative rate limit of 5 seconds between each request
  Sys.sleep(5)
  
}


# add entries from last page to data frame 
##########################################

# perform GET request for last page
resp_venues_ger_lastpage <-
  GET(url = "https://app.ticketmaster.com/discovery/v2/venues.json?",
      query = list(
        countryCode = "DE",           # set countryCode as Germany
        apikey = api_key,             # provide secret API key to successfully call API
        page = (i + 1),               # last page number after loop with not all entries
        locale = "*" ,                # use * to match all locales
        size = size_param             # adjust number of entries per page
      )
  )


# extract content from response object
content_json_lastpage <- content(resp_venues_ger_lastpage, as = "text")

# convert JSON object in R object
content_venues_lastpage <- fromJSON(content_json_lastpage)

# create data frame for each page
# sometimes location element is missing 
# then missings for longitude  and latitude 
if (is.null(content_venues_lastpage$`_embedded`$venues$location$longitude)) {
  df_venues_lastpage <- data.frame(
    "name" = content_venues_lastpage$`_embedded`$venues$name, 
    "city" = content_venues_lastpage$`_embedded`$venues$city$name, 
    "postalCode" = content_venues_lastpage$`_embedded`$venues$postalCode, 
    "address" = content_venues_lastpage$`_embedded`$venues$address$line1,
    "url" = content_venues_lastpage$`_embedded`$venues$url,
    "longitude" = rep(NA, length(content_venues_lastpage$`_embedded`$venues$name)),
    "latitude" = rep(NA, length(content_venues_lastpage$`_embedded`$venues$name))
  )
} else {
  df_venues_lastpage <- data.frame(
    "name" = content_venues_lastpage$`_embedded`$venues$name, 
    "city" = content_venues_lastpage$`_embedded`$venues$city$name, 
    "postalCode" = content_venues_lastpage$`_embedded`$venues$postalCode, 
    "address" = content_venues_lastpage$`_embedded`$venues$address$line1,
    "url" = content_venues_lastpage$`_embedded`$venues$url,
    "longitude" = content_venues_lastpage$`_embedded`$venues$location$longitude,
    "latitude" = content_venues_lastpage$`_embedded`$venues$location$latitude
  )
}


# add both data frames together
###############################

df_venues_final <- rbind(df_venues_all, df_venues_lastpage)

# show structure of final data frame
str(df_venues_final)
```

\

## Exercise 5: Visualizing the extracted data

A map of Germany that indicates the locations of the event venues across Germany is created. To do so, I first change the data type of the `longitude` and `latitude` variables to numeric. 

```{r ex5_coord_numeric}
# change data type of longitude and latitude variable to numeric
df_venues_final$longitude <- as.numeric(df_venues_final$longitude)
df_venues_final$latitude <- as.numeric(df_venues_final$latitude)
```

Secondly, I set coordinate values to `NA` that lie way beyond the German borders. The coordinate ranges have been derived from the extreme points of Germany as listed on Wikipedia.

```{r ex5_coord_NA}
# set coordinates outside the given range to NA
# do this for latitude
df_venues_final$latitude <- ifelse(
  # if latitude values are between the given range...
  between(df_venues_final$latitude, 
          47.271679,  # min latitude
          55.0846), # max latitude
  # ... then keep them as they are ...
  df_venues_final$latitude, 
  # ... else set them to NA
  NA)

# do this for longitude
df_venues_final$longitude <- ifelse(
  # if longitude values are between the given range...
  between(df_venues_final$longitude, 
          5.866944,  # min longitude 
          15.043611), # max longitude 
  # ... then keep them as they are ...
  df_venues_final$longitude, 
  # ... else set them to NA
  NA)
```

\

Lastly, I create the map:

```{r ex5_map, warning = F}
# visualizing the extract data by creating a map
ggplot(data = df_venues_final, mapping = aes(x = longitude, y = latitude)) +
  # plot map of germany
  geom_polygon(
    aes(x = long, y = lat, group = group), data = map_data("world", region = "Germany"),
    fill = "grey90",color = "black") +
  # project a portion of the earth onto a flat 2D plane
  coord_quickmap() +
  # add white background
  theme_void() +
  # add title and caption
  labs(title = "Event locations across Germany", caption = "Source: ticketmaster.com") +
  # make plot niced
  theme(title = element_text(size = 8, face = 'bold'),  # change font size of title
        plot.title = element_text(hjust = 0.5),  # title in the middle of the plot
        plot.caption = element_text(face = "italic")) +  # change font of caption
  # highlight venues with points
  # adjust opacity to avoid overplotting and visualize areas with many venues
  # darker than areas with less venues
  geom_point(alpha = 0.2)
```



\

## Exercise 6: Event locations in other countries

Repeating exercise 2 for another European country leads to the same results as above. The only thing, I additionally figured out is the country code in the venue search documentation. Moreover, in exercise 3, describing what I see in the list element after the first `GET()` request is identical to above. 

To repeat the analysis for another European country, I put the code for exercise 3 and 4 into a function called `func_venues()` and the code for the map created in exercise 6 inside a function called `func_map_venues()`. 
This is very efficient as I can change the choice of what European country I want to use very easy.

```{r function_venues_data, echo = F}
##########################
# function for venues data
##########################

# the function func_venues() extracts all event venues in the specified country
# with some useful information such as the coordinates.
# input arguments are:
  # country: specify the country code
  # size: specify the number of results per page (should be a high number like 200)
  # api_key: the personal API key

func_venues <- function(country, size, api_key) {
  
  #############
  # Exercise 3
  ############
  
  # get data for page 0
  #####################
  
  # perform GET request
  resp_venues_page0 <-
    GET(url = "https://app.ticketmaster.com/discovery/v2/venues.json?",
        query = list(
          apikey = api_key,       # provide secret API key to successfully call API
          countryCode = country,  # country code as defined in function
          locale = "*"            # use * to match all locales
        )
    )
  
  # function displays a warning if GET() request fails
  stop_for_status(resp_venues_page0)
  
  # extract content from response object
  content_json_page0 <- content(resp_venues_page0, as = "text")
  
  # convert JSON object in R object
  content_venues_page0 <- fromJSON(content_json_page0)
  
  # create data frame with results from first page
  df_venues_firstpage <- data.frame(
  "name" = content_venues_page0$`_embedded`$venues$name, 
  "city" = content_venues_page0$`_embedded`$venues$city$name, 
  "postalCode" = content_venues_page0$`_embedded`$venues$postalCode, 
  "address" = content_venues_page0$`_embedded`$venues$address$line1,
  "url" = content_venues_page0$`_embedded`$venues$url,
  "longitude" = content_venues_page0$`_embedded`$venues$location$longitude,
  "latitude" = content_venues_page0$`_embedded`$venues$location$latitude
  )
  
  
  ############
  # Exercise 4
  ############
  
  # how many results are there in total?
  n <- as.numeric(content_venues_page0$page$totalElements)  

  # how many full pages do we have?
  full_pages <- as.numeric(floor(n/size))  
  
  # how many venues are on last page
  results_last_page <- n - (full_pages * size)  
  
  # create empty data frame with right dimensions which is filled during loop 
  df_venues_all <- data.frame(
    "name" = character(full_pages * size), 
    "city" = character(full_pages * size), 
    "postalCode" = character(full_pages * size), 
    "address" = character(full_pages * size),
    "url" = character(full_pages * size), 
    "longitude" = character(full_pages * size),
    "latitude" = character(full_pages * size)
  )
  
  # note: since page starts at 0, the full_pages for the loop are one less
  loop_pages <- full_pages - 1
  
  
  # for-loop
  ##########
  
  for (i in 0:loop_pages) {
  
  # perform GET request for each page
  resp_venues_pagei <-
    GET(url = "https://app.ticketmaster.com/discovery/v2/venues.json?",
        query = list(
          countryCode = country,  # set countryCode as Germany
          apikey = api_key,       # provide secret API key to successfully call API
          page = i,               # page number
          locale = "*",           # use * to match all locales
          size = size             # adjust results per page
        )
    )
  
  
  # extract content from response object
  content_json_pagei <- content(resp_venues_pagei, as = "text")
  
  # convert JSON object in R object
  content_venues <- fromJSON(content_json_pagei)
  
  # create data frame for each page
  # sometimes location element is missing. In this case, I set values of 
  # longitude  and latitude to NA
  if (is.null(content_venues$`_embedded`$venues$location$longitude)) {
    df_venues_pagei <- data.frame(
      "name" = content_venues$`_embedded`$venues$name, 
      "city" = content_venues$`_embedded`$venues$city$name, 
      "postalCode" = content_venues$`_embedded`$venues$postalCode, 
      "address" = content_venues$`_embedded`$venues$address$line1,
      "url" = content_venues$`_embedded`$venues$url,
      "longitude" = rep(NA, size),
      "latitude" = rep(NA, size)
    )
  } else {
    df_venues_pagei <- data.frame(
      "name" = content_venues$`_embedded`$venues$name, 
      "city" = content_venues$`_embedded`$venues$city$name, 
      "postalCode" = content_venues$`_embedded`$venues$postalCode, 
      "address" = content_venues$`_embedded`$venues$address$line1,
      "url" = content_venues$`_embedded`$venues$url,
      "longitude" = content_venues$`_embedded`$venues$location$longitude,
      "latitude" = content_venues$`_embedded`$venues$location$latitude
    )
  }

  # create index 
  j <- i + 1
  
  # calculate index to fill empty data frame
  index <- ((j - 1) * size + 1):(size * j)
  
  # append data frame of each page to full data frame
  df_venues_all[index, ] <- df_venues_pagei
  
  # respect rate limit: 5 requests per second
  # according to the lecture this would be using Sys.sleep(0.2)
  # I don't know why, but using this rate limit my code did not work.
  # I always received a HTTP status code of 429 meaning that I made too many requests.
  # Thus, I use a more conservative rate limit of 2 seconds between each request
  Sys.sleep(5)
  
}
  
  
  # add entries from last page to data frame 
  ##########################################
  
  # perform GET request for each page
  resp_venues_lastpage <-
    GET(url = "https://app.ticketmaster.com/discovery/v2/venues.json?",
        query = list(
          countryCode = country,  # set countryCode according to input
          apikey = api_key,       # provide secret API key to successfully call API
          page = (i + 1),           # last page number after loop with not all entries
          locale = "*",           # use * to match all locales
          size = size
        )
    )
  
  
  # extract content from response object
  content_json_lastpage <- content(resp_venues_lastpage, as = "text")
  
  # convert JSON object in R object
  content_venues_lastpage <- fromJSON(content_json_lastpage)
  
  # create data frame for each page
  # sometimes location element is missing 
  # then missings for longitude  and latitude 
  if (is.null(content_venues_lastpage$`_embedded`$venues$location$longitude)) {
    df_venues_lastpage <- data.frame(
      "name" = content_venues_lastpage$`_embedded`$venues$name, 
      "city" = content_venues_lastpage$`_embedded`$venues$city$name, 
      "postalCode" = content_venues_lastpage$`_embedded`$venues$postalCode, 
      "address" = content_venues_lastpage$`_embedded`$venues$address$line1,
      "url" = content_venues_lastpage$`_embedded`$venues$url,
      "longitude" = rep(NA, results_last_page),
      "latitude" = rep(NA, results_last_page)
    )
  } else {
    df_venues_lastpage <- data.frame(
      "name" = content_venues_lastpage$`_embedded`$venues$name, 
      "city" = content_venues_lastpage$`_embedded`$venues$city$name, 
      "postalCode" = content_venues_lastpage$`_embedded`$venues$postalCode, 
      "address" = content_venues_lastpage$`_embedded`$venues$address$line1,
      "url" = content_venues_lastpage$`_embedded`$venues$url,
      "longitude" = content_venues_lastpage$`_embedded`$venues$location$longitude,
      "latitude" = content_venues_lastpage$`_embedded`$venues$location$latitude
    )
  }
  
  
  # append result to full data frame
  ##################################
  
  df_venues_final <- rbind(df_venues_all, df_venues_lastpage)
  
  # change data type of longitude and latitude as numeric
  #######################################################
  
  df_venues_final[, c("longitude", "latitude")] <- apply(df_venues_final[, c("longitude", "latitude")],
                                                         MARGIN = 2,
                                                         as.numeric)
  # results from exercise 3 and 4
  ###############################
  
  return(list(df_venues_firstpage, df_venues_final))
}



####################################
# function for map with event venues
####################################

# this function produces a map which highlights the event venues in the
# specified country. The input arguments are:
  # data: data with coordinates (longitude and latitude) of the event venues
  # country: full name of country from which the coordinates are, e.g. "Germany"
  # lat_min: minimal latitude derived from wikipedia "southernmost point"
  # lat_max: minimal latitude derived from wikipedia "northernmost point"
  # long_min: minimal longitude derived from wikipedia "westernmost point"
  # long_max: maximal longitude derived from wikipedia "easternmost point"


func_map <- function(data, country, lat_min, lat_max, long_min, long_max) {
  

  # set coordinates outside the range to NA
  #########################################
  
  # for latitude
  data$latitude <- ifelse(
    # if lat values are between min and max of map data...
    between(data$latitude, 
            lat_min,  # min lat of map data
            lat_max), # max lat of map data
    # ... then keep lat ...
    data$latitude, 
    # ... else set it missing
    NA)
  
  data$longitude <- ifelse(
    # if lat values are between min and max of map data...
    between(data$longitude, 
            long_min,  # min long of map data
            long_max), # max long of map data
    # ... then keep long ...
    data$longitude, 
    # ... else set it missing
    NA)
  
  
  # create plot
  #############
  
  plot <- ggplot(data = data, mapping = aes(x = longitude, y = latitude)) +
    # plot country map
    geom_polygon(
      aes(x = long, y = lat, group = group), data = map_data("world", region = country),
      fill = "grey90",color = "black") +
    # project a portion of the earth onto a flat 2D plane
    coord_quickmap() +
    # add white background
    theme_void() +
    # add title and caption
    labs(title = paste("Event locations across", country), caption = "Source: ticketmaster.com") +
    # change font and font size of title and caption
    theme(title = element_text(size = 8, face = 'bold'), 
          plot.title = element_text(hjust = 0.5),
          plot.caption = element_text(face = "italic")) + 
    # highlight venues with points
    # adjust opacity to avoid overplotting and visualize areas with many venues
    # darker than areas with less venues
    geom_point(alpha = 0.2)
  
  
  return(plot)
  
}
```



\

I extract the venues data for Austria and create the map using my two functions.  

```{r ex6_austria, warning = F}
# extract data
df_austria_list <- func_venues("AT", 200, api_key)

# show structure of first page results (exercise 3)
df_austria_ex3 <- df_austria_list[[1]]
str(df_austria_ex3)

# show structure of data frame with all event venues in Austria (exercise 4)
df_austria_ex4 <- df_austria_list[[2]]
str(df_austria_ex4)

# create map (extreme points are extracted from Wikipedia)
func_map(df_austria_ex4, "Austria", 46.3725, 49.020556, 9.530833, 17.160556)
```


\

To show that my function works fine, I create a map for the Netherlands:

```{r ex6_netherlands, warning = F}
# extract data
df_netherlands_list <- func_venues("NL", 500, api_key)

# show structure of first page results (exercise 3)
df_netherlands_ex3 <- df_netherlands_list[[1]]
str(df_netherlands_ex3)

# show structure of dataa frame with all event venues in the Netherlands (exercise 4)
df_netherlands_ex4 <- df_netherlands_list[[2]]
str(df_netherlands_ex4)

# create map (extreme points are extracted from Wikipedia)
func_map(df_netherlands_ex4, "Netherlands", 50.750417, 53.465556, 3.358333, 7.227778)
```

